#!/usr/bin/env python3
"""
êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰ ê¸°ë°˜ í¬ë¡¤ëŸ¬
ê±´ì¶• ì™¸ì¥ì¬ ì´ë¯¸ì§€ë¥¼ êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰ì„ í†µí•´ ìˆ˜ì§‘í•˜ëŠ” ëª¨ë“ˆ
"""

import os
import time
import requests
import hashlib
import json
from urllib.parse import urlencode, urlparse
from typing import List, Dict, Optional
import logging
from pathlib import Path

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException
from webdriver_manager.chrome import ChromeDriverManager

from PIL import Image
import io

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class GoogleImageCrawler:
    """êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰ì„ í†µí•œ ì´ë¯¸ì§€ ìˆ˜ì§‘ í´ë˜ìŠ¤"""
    
    def __init__(self, headless: bool = True, timeout: int = 15):
        """
        êµ¬ê¸€ ì´ë¯¸ì§€ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
        
        Args:
            headless: ë¸Œë¼ìš°ì € í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ì—¬ë¶€
            timeout: í˜ì´ì§€ ë¡œë”© íƒ€ì„ì•„ì›ƒ (ì´ˆ)
        """
        self.timeout = timeout
        self.headless = headless
        
        # Chrome ì˜µì…˜ ì„¤ì •
        self.chrome_options = Options()
        if headless:
            self.chrome_options.add_argument('--headless')
        self.chrome_options.add_argument('--no-sandbox')
        self.chrome_options.add_argument('--disable-dev-shm-usage')
        self.chrome_options.add_argument('--disable-gpu')
        self.chrome_options.add_argument('--window-size=1920,1080')
        
        # User-Agent ì„¤ì • (ë´‡ ì°¨ë‹¨ ë°©ì§€)
        self.chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')
        
        # ê±´ì¶• ì™¸ì¥ì¬ë³„ ê²€ìƒ‰ í‚¤ì›Œë“œ (í•œêµ­ì–´ + ì˜ì–´)
        self.search_keywords = {
            'brick': [
                'ì¡°ì  ì™¸ë²½',
                'ë²½ëŒ ì‹œê³µ ì‚¬ë¡€', 
                'ì ë²½ëŒ ì™¸ê´€',
                'ì¹˜ì¥ ë²½ëŒ',
                'brick wall exterior',
                'brick building facade',
                'red brick architecture'
            ],
            'stucco': [
                'ìŠ¤íƒ€ì½” ë§ˆê° ì£¼íƒ',
                'ë“œë¼ì´ë¹„íŠ¸ ì™¸ë²½',
                'ë¯¸ì¥ ë§ˆê°',
                'í™”ì´íŠ¸ ìŠ¤íƒ€ì½”',
                'stucco exterior wall',
                'dryvit building',
                'white stucco house'
            ],
            'metal': [
                'ì§•í¬ íŒ¨ë„ ì‹œê³µ',
                'ê¸ˆì† ì™¸ì¥ì¬',
                'ì•Œë£¨ë¯¸ëŠ„ íŒ¨ë„ ê±´ë¬¼',
                'zinc panel building',
                'metal cladding exterior',
                'aluminum facade panel'
            ],
            'stone': [
                'í™”ê°•ì„ ì™¸ë²½',
                'ì„ì¬ ì™¸ì¥ ë§ˆê°',
                'ëŒ€ë¦¬ì„ ê±´ì¶•ë¬¼',
                'ê±´ì¶•ë¬¼ ì„ì¬ íƒ€ì¼',
                'granite exterior wall',
                'stone cladding building',
                'marble facade architecture'
            ],
            'wood': [
                'ëª©ì¬ ì‚¬ì´ë”© ì‹œê³µ',
                'ìš°ë“œ ì™¸ì¥ì¬',
                'ëª©ì¡° ì£¼íƒ ì™¸ê´€',
                'ë‚˜ë¬´ ì™¸ë²½',
                'wood siding exterior',
                'wooden cladding house',
                'timber facade building'
            ]
        }
        
        # ì„¸ì…˜ ì„¤ì •
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
    
    def _get_driver(self) -> webdriver.Chrome:
        """Chrome ë“œë¼ì´ë²„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        try:
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=self.chrome_options)
            driver.set_page_load_timeout(self.timeout)
            return driver
        except Exception as e:
            logger.error(f"ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def _build_google_images_url(self, keyword: str, image_size: str = 'medium') -> str:
        """
        êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰ URL ìƒì„±
        
        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            image_size: ì´ë¯¸ì§€ í¬ê¸° ('small', 'medium', 'large')
            
        Returns:
            êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰ URL
        """
        # êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰ íŒŒë¼ë¯¸í„°
        params = {
            'q': keyword,
            'tbm': 'isch',  # ì´ë¯¸ì§€ ê²€ìƒ‰
            'hl': 'ko',     # í•œêµ­ì–´
            'safe': 'off',  # ì„¸ì´í”„ì„œì¹˜ ë„ê¸°
            'tbs': f'isz:{image_size[0]}'  # ì´ë¯¸ì§€ í¬ê¸° (m=medium, l=large, s=small)
        }
        
        base_url = 'https://www.google.com/search'
        return f"{base_url}?{urlencode(params)}"
    
    def collect_image_urls_from_keyword(self, keyword: str, max_images: int = 50) -> List[str]:
        """
        íŠ¹ì • í‚¤ì›Œë“œë¡œ êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰í•˜ì—¬ ì´ë¯¸ì§€ URL ìˆ˜ì§‘
        
        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            max_images: ìµœëŒ€ ìˆ˜ì§‘í•  ì´ë¯¸ì§€ ìˆ˜
            
        Returns:
            ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸
        """
        driver = None
        image_urls = []
        
        try:
            # ë“œë¼ì´ë²„ ì´ˆê¸°í™”
            driver = self._get_driver()
            
            # êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰ í˜ì´ì§€ë¡œ ì´ë™
            search_url = self._build_google_images_url(keyword)
            logger.info(f"êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰: {keyword}")
            logger.debug(f"ê²€ìƒ‰ URL: {search_url}")
            
            driver.get(search_url)
            
            # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            WebDriverWait(driver, self.timeout).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "img[data-src], img[src]"))
            )
            
            # ìŠ¤í¬ë¡¤í•˜ì—¬ ë” ë§ì€ ì´ë¯¸ì§€ ë¡œë“œ
            self._scroll_and_load_images(driver, max_images)
            
            # ì´ë¯¸ì§€ ìš”ì†Œë“¤ ì°¾ê¸°
            img_elements = driver.find_elements(By.CSS_SELECTOR, "img[data-src], img[src]")
            logger.info(f"ë°œê²¬ëœ ì´ë¯¸ì§€ ìš”ì†Œ: {len(img_elements)}ê°œ")
            
            for i, img_element in enumerate(img_elements):
                if len(image_urls) >= max_images:
                    break
                
                try:
                    # ì´ë¯¸ì§€ URL ì¶”ì¶œ (data-src ìš°ì„ , ì—†ìœ¼ë©´ src)
                    img_url = img_element.get_attribute('data-src') or img_element.get_attribute('src')
                    
                    if img_url and self._is_valid_image_url(img_url):
                        # êµ¬ê¸€ í”„ë¡ì‹œ URLì„ ì‹¤ì œ ì´ë¯¸ì§€ URLë¡œ ë³€í™˜
                        actual_url = self._extract_actual_image_url(img_url)
                        if actual_url:
                            image_urls.append(actual_url)
                            logger.debug(f"ì´ë¯¸ì§€ URL ìˆ˜ì§‘: {actual_url}")
                
                except Exception as e:
                    logger.debug(f"ì´ë¯¸ì§€ ìš”ì†Œ ì²˜ë¦¬ ì˜¤ë¥˜ (ì¸ë±ìŠ¤ {i}): {e}")
                    continue
            
            logger.info(f"í‚¤ì›Œë“œ '{keyword}'ë¡œ {len(image_urls)}ê°œ ì´ë¯¸ì§€ URL ìˆ˜ì§‘ ì™„ë£Œ")
            return image_urls
            
        except TimeoutException:
            logger.error(f"í˜ì´ì§€ ë¡œë”© íƒ€ì„ì•„ì›ƒ: {keyword}")
            return image_urls
        except WebDriverException as e:
            logger.error(f"Selenium ì˜¤ë¥˜: {keyword} - {e}")
            return image_urls
        except Exception as e:
            logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {keyword} - {e}")
            return image_urls
        finally:
            if driver:
                driver.quit()
    
    def _scroll_and_load_images(self, driver: webdriver.Chrome, target_images: int):
        """
        í˜ì´ì§€ë¥¼ ìŠ¤í¬ë¡¤í•˜ì—¬ ë” ë§ì€ ì´ë¯¸ì§€ ë¡œë“œ
        
        Args:
            driver: Selenium ë“œë¼ì´ë²„
            target_images: ëª©í‘œ ì´ë¯¸ì§€ ìˆ˜
        """
        last_height = driver.execute_script("return document.body.scrollHeight")
        scroll_attempts = 0
        max_scroll_attempts = 10
        
        while scroll_attempts < max_scroll_attempts:
            # í˜ì´ì§€ ëê¹Œì§€ ìŠ¤í¬ë¡¤
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            
            # ë¡œë”© ëŒ€ê¸°
            time.sleep(2)
            
            # "ê²°ê³¼ ë”ë³´ê¸°" ë²„íŠ¼ í´ë¦­ ì‹œë„
            try:
                more_results_button = driver.find_element(By.CSS_SELECTOR, "input[value*='ê²°ê³¼ ë”ë³´ê¸°'], input[value*='Show more results']")
                if more_results_button.is_displayed():
                    driver.execute_script("arguments[0].click();", more_results_button)
                    time.sleep(3)
                    logger.debug("'ê²°ê³¼ ë”ë³´ê¸°' ë²„íŠ¼ í´ë¦­")
            except NoSuchElementException:
                pass
            except Exception as e:
                logger.debug(f"'ê²°ê³¼ ë”ë³´ê¸°' ë²„íŠ¼ í´ë¦­ ì‹¤íŒ¨: {e}")
            
            # ìƒˆë¡œìš´ ë†’ì´ í™•ì¸
            new_height = driver.execute_script("return document.body.scrollHeight")
            
            # í˜„ì¬ ë¡œë“œëœ ì´ë¯¸ì§€ ìˆ˜ í™•ì¸
            current_images = len(driver.find_elements(By.CSS_SELECTOR, "img[data-src], img[src]"))
            logger.debug(f"í˜„ì¬ ë¡œë“œëœ ì´ë¯¸ì§€: {current_images}ê°œ")
            
            # ëª©í‘œ ì´ë¯¸ì§€ ìˆ˜ì— ë„ë‹¬í–ˆê±°ë‚˜ ë” ì´ìƒ ìŠ¤í¬ë¡¤í•  ìˆ˜ ì—†ìœ¼ë©´ ì¤‘ë‹¨
            if current_images >= target_images or new_height == last_height:
                break
                
            last_height = new_height
            scroll_attempts += 1
        
        logger.debug(f"ìŠ¤í¬ë¡¤ ì™„ë£Œ: {scroll_attempts}íšŒ ì‹œë„")
    
    def _extract_actual_image_url(self, google_url: str) -> Optional[str]:
        """
        êµ¬ê¸€ í”„ë¡ì‹œ URLì—ì„œ ì‹¤ì œ ì´ë¯¸ì§€ URL ì¶”ì¶œ
        
        Args:
            google_url: êµ¬ê¸€ ì´ë¯¸ì§€ URL
            
        Returns:
            ì‹¤ì œ ì´ë¯¸ì§€ URL ë˜ëŠ” None
        """
        try:
            # êµ¬ê¸€ ì´ë¯¸ì§€ í”„ë¡ì‹œ URL íŒ¨í„´ í™•ì¸
            if 'googleusercontent.com' in google_url or 'ggpht.com' in google_url:
                return google_url
            
            # ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ URLì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
            if any(ext in google_url.lower() for ext in ['.jpg', '.jpeg', '.png', '.webp']):
                return google_url
            
            # êµ¬ê¸€ ê²€ìƒ‰ ê²°ê³¼ URLì—ì„œ ì‹¤ì œ URL ì¶”ì¶œ ì‹œë„
            if 'imgurl=' in google_url:
                from urllib.parse import parse_qs, urlparse
                parsed = urlparse(google_url)
                params = parse_qs(parsed.query)
                if 'imgurl' in params:
                    return params['imgurl'][0]
            
            return google_url
            
        except Exception as e:
            logger.debug(f"URL ì¶”ì¶œ ì˜¤ë¥˜: {google_url} - {e}")
            return None
    
    def _is_valid_image_url(self, url: str) -> bool:
        """
        ì´ë¯¸ì§€ URL ìœ íš¨ì„± ê²€ì‚¬
        
        Args:
            url: ê²€ì‚¬í•  URL
            
        Returns:
            ìœ íš¨ì„± ì—¬ë¶€
        """
        if not url or not url.startswith(('http://', 'https://')):
            return False
        
        # êµ¬ê¸€ ë¡œê³ ë‚˜ ì•„ì´ì½˜ ë“± ì œì™¸
        exclude_patterns = [
            'logo', 'icon', 'button', 'arrow', 'search',
            'google.com/images/branding', 'gstatic.com',
            'data:image', 'base64'
        ]
        
        url_lower = url.lower()
        if any(pattern in url_lower for pattern in exclude_patterns):
            return False
        
        # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¥ì ë˜ëŠ” êµ¬ê¸€ ì´ë¯¸ì§€ ì„œë¹„ìŠ¤ URL í™•ì¸
        valid_patterns = [
            '.jpg', '.jpeg', '.png', '.webp', '.bmp',
            'googleusercontent.com', 'ggpht.com'
        ]
        
        return any(pattern in url_lower for pattern in valid_patterns)
    
    def collect_images_for_category(self, category: str, max_images_per_keyword: int = 20) -> List[str]:
        """
        íŠ¹ì • ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ ëª¨ë“  í‚¤ì›Œë“œë¡œ ì´ë¯¸ì§€ URL ìˆ˜ì§‘
        
        Args:
            category: ì¹´í…Œê³ ë¦¬ëª… ('brick', 'stucco', 'metal', 'stone', 'wood')
            max_images_per_keyword: í‚¤ì›Œë“œë‹¹ ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜
            
        Returns:
            ìˆ˜ì§‘ëœ ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸
        """
        if category not in self.search_keywords:
            logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬: {category}")
            return []
        
        all_image_urls = []
        keywords = self.search_keywords[category]
        
        for keyword in keywords:
            logger.info(f"=== '{keyword}' í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹œì‘ ===")
            
            try:
                urls = self.collect_image_urls_from_keyword(keyword, max_images_per_keyword)
                all_image_urls.extend(urls)
                
                logger.info(f"í‚¤ì›Œë“œ '{keyword}': {len(urls)}ê°œ URL ìˆ˜ì§‘")
                
                # í‚¤ì›Œë“œ ê°„ ìš”ì²­ ê°„ê²© (êµ¬ê¸€ ì°¨ë‹¨ ë°©ì§€)
                time.sleep(3)
                
            except Exception as e:
                logger.error(f"í‚¤ì›Œë“œ '{keyword}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        # ì¤‘ë³µ ì œê±°
        unique_urls = list(set(all_image_urls))
        logger.info(f"ì¹´í…Œê³ ë¦¬ '{category}' ì´ ìˆ˜ì§‘: {len(all_image_urls)}ê°œ â†’ ì¤‘ë³µ ì œê±° í›„: {len(unique_urls)}ê°œ")
        
        return unique_urls
    
    def collect_all_categories(self, max_images_per_category: int = 100) -> Dict[str, List[str]]:
        """
        ëª¨ë“  ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ ì´ë¯¸ì§€ URL ìˆ˜ì§‘
        
        Args:
            max_images_per_category: ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜
            
        Returns:
            ì¹´í…Œê³ ë¦¬ë³„ ì´ë¯¸ì§€ URL ë”•ì…”ë„ˆë¦¬
        """
        results = {}
        
        for category in self.search_keywords.keys():
            logger.info(f"\nğŸ—ï¸ === {category.upper()} ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ ì‹œì‘ ===")
            
            # í‚¤ì›Œë“œë‹¹ ì´ë¯¸ì§€ ìˆ˜ ê³„ì‚°
            num_keywords = len(self.search_keywords[category])
            images_per_keyword = max(10, max_images_per_category // num_keywords)
            
            try:
                urls = self.collect_images_for_category(category, images_per_keyword)
                
                # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
                if len(urls) > max_images_per_category:
                    urls = urls[:max_images_per_category]
                
                results[category] = urls
                logger.info(f"âœ… {category} ì¹´í…Œê³ ë¦¬ ì™„ë£Œ: {len(urls)}ê°œ URL")
                
                # ì¹´í…Œê³ ë¦¬ ê°„ ëŒ€ê¸° ì‹œê°„
                time.sleep(5)
                
            except Exception as e:
                logger.error(f"âŒ {category} ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                results[category] = []
        
        return results


def test_google_crawler():
    """êµ¬ê¸€ ì´ë¯¸ì§€ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ” êµ¬ê¸€ ì´ë¯¸ì§€ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” (í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ë¹„í™œì„±í™”ë¡œ í…ŒìŠ¤íŠ¸)
    crawler = GoogleImageCrawler(headless=False, timeout=20)
    
    # ë‹¨ì¼ í‚¤ì›Œë“œ í…ŒìŠ¤íŠ¸
    test_keyword = "ë²½ëŒ ì™¸ë²½"
    print(f"í…ŒìŠ¤íŠ¸ í‚¤ì›Œë“œ: {test_keyword}")
    
    urls = crawler.collect_image_urls_from_keyword(test_keyword, max_images=10)
    
    print(f"\nìˆ˜ì§‘ ê²°ê³¼: {len(urls)}ê°œ URL")
    for i, url in enumerate(urls[:5], 1):
        print(f"  {i}. {url}")
    
    if len(urls) > 5:
        print(f"  ... ì™¸ {len(urls) - 5}ê°œ")
    
    return len(urls) > 0


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    success = test_google_crawler()
    
    if success:
        print("\nâœ… êµ¬ê¸€ ì´ë¯¸ì§€ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
    else:
        print("\nâŒ êµ¬ê¸€ ì´ë¯¸ì§€ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")