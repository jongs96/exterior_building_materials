#!/usr/bin/env python3
"""
ê°œì„ ëœ êµ¬ê¸€ ì´ë¯¸ì§€ í¬ë¡¤ëŸ¬
ì‹¤ì œ ì´ë¯¸ì§€ í´ë¦­ì„ í†µí•´ ì›ë³¸ URLì„ ì¶”ì¶œí•˜ëŠ” ë°©ì‹
"""

import os
import time
import requests
import json
from urllib.parse import urlencode, urlparse, parse_qs
from typing import List, Dict, Optional
import logging
from pathlib import Path
import re

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException
from selenium.webdriver.common.action_chains import ActionChains
from webdriver_manager.chrome import ChromeDriverManager

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ImprovedGoogleImageCrawler:
    """ê°œì„ ëœ êµ¬ê¸€ ì´ë¯¸ì§€ í¬ë¡¤ëŸ¬ - ì‹¤ì œ ì´ë¯¸ì§€ í´ë¦­ ë°©ì‹"""
    
    def __init__(self, headless: bool = True, timeout: int = 20):
        """
        í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
        
        Args:
            headless: í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ì—¬ë¶€
            timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)
        """
        self.timeout = timeout
        self.headless = headless
        
        # Chrome ì˜µì…˜ ì„¤ì •
        self.chrome_options = Options()
        if headless:
            self.chrome_options.add_argument('--headless')
        
        # ê¸°ë³¸ ì˜µì…˜ë“¤
        self.chrome_options.add_argument('--no-sandbox')
        self.chrome_options.add_argument('--disable-dev-shm-usage')
        self.chrome_options.add_argument('--disable-gpu')
        self.chrome_options.add_argument('--window-size=1920,1080')
        self.chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        
        # User-Agent ì„¤ì •
        self.chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')
        
        # ê²€ìƒ‰ í‚¤ì›Œë“œ (í•œêµ­ì–´ ì¤‘ì‹¬)
        self.search_keywords = {
            'brick': [
                'ì¡°ì  ì™¸ë²½',
                'ë²½ëŒ ì™¸ê´€',
                'ì ë²½ëŒ ê±´ë¬¼',
                'ì¹˜ì¥ë²½ëŒ',
                'brick exterior wall'
            ],
            'stucco': [
                'ìŠ¤íƒ€ì½” ì™¸ë²½',
                'ë“œë¼ì´ë¹„íŠ¸ ë§ˆê°',
                'ë¯¸ì¥ ì™¸ë²½',
                'í™”ì´íŠ¸ ìŠ¤íƒ€ì½”',
                'stucco exterior'
            ],
            'metal': [
                'ì§•í¬ íŒ¨ë„',
                'ê¸ˆì† ì™¸ì¥ì¬',
                'ì•Œë£¨ë¯¸ëŠ„ íŒ¨ë„',
                'ê¸ˆì† ì‚¬ì´ë”©',
                'metal panel facade'
            ],
            'stone': [
                'ì„ì¬ ì™¸ë²½',
                'í™”ê°•ì„ ì™¸ì¥',
                'ëŒ€ë¦¬ì„ ì™¸ë²½',
                'ì„ì¬ ë§ˆê°',
                'stone cladding'
            ],
            'wood': [
                'ëª©ì¬ ì‚¬ì´ë”©',
                'ìš°ë“œ ì™¸ì¥ì¬',
                'ëª©ì¬ ì™¸ë²½',
                'ë‚˜ë¬´ ì‚¬ì´ë”©',
                'wood siding'
            ]
        }
    
    def _get_driver(self) -> webdriver.Chrome:
        """Chrome ë“œë¼ì´ë²„ ìƒì„±"""
        try:
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=self.chrome_options)
            driver.set_page_load_timeout(self.timeout)
            
            # ìë™í™” ê°ì§€ ë°©ì§€
            driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            
            return driver
        except Exception as e:
            logger.error(f"ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def collect_image_urls_from_keyword(self, keyword: str, max_images: int = 30) -> List[str]:
        """
        í‚¤ì›Œë“œë¡œ êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰í•˜ì—¬ URL ìˆ˜ì§‘
        
        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            max_images: ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜
            
        Returns:
            ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸
        """
        driver = None
        image_urls = []
        
        try:
            driver = self._get_driver()
            
            # êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰ URL ìƒì„±
            search_url = f"https://www.google.com/search?q={keyword}&tbm=isch&hl=ko"
            logger.info(f"ê²€ìƒ‰ ì‹œì‘: {keyword}")
            
            driver.get(search_url)
            time.sleep(3)
            
            # ì¿ í‚¤ ë™ì˜ ë²„íŠ¼ ì²˜ë¦¬
            try:
                accept_button = driver.find_element(By.XPATH, "//button[contains(text(), 'ëª¨ë‘ í—ˆìš©') or contains(text(), 'Accept all')]")
                accept_button.click()
                time.sleep(2)
            except:
                pass
            
            # ì´ë¯¸ì§€ ì¸ë„¤ì¼ë“¤ ì°¾ê¸°
            self._scroll_to_load_images(driver, max_images)
            
            # ì´ë¯¸ì§€ ì¸ë„¤ì¼ ìš”ì†Œë“¤ ê°€ì ¸ì˜¤ê¸°
            thumbnail_elements = driver.find_elements(By.CSS_SELECTOR, "img[data-src]")
            logger.info(f"ë°œê²¬ëœ ì¸ë„¤ì¼: {len(thumbnail_elements)}ê°œ")
            
            # ê° ì¸ë„¤ì¼ì„ í´ë¦­í•˜ì—¬ ì›ë³¸ ì´ë¯¸ì§€ URL ì¶”ì¶œ
            for i, thumbnail in enumerate(thumbnail_elements[:max_images]):
                if len(image_urls) >= max_images:
                    break
                
                try:
                    # ì¸ë„¤ì¼ í´ë¦­
                    driver.execute_script("arguments[0].click();", thumbnail)
                    time.sleep(1.5)
                    
                    # ì›ë³¸ ì´ë¯¸ì§€ URL ì¶”ì¶œ ì‹œë„
                    original_url = self._extract_original_image_url(driver)
                    
                    if original_url and self._is_valid_image_url(original_url):
                        image_urls.append(original_url)
                        logger.debug(f"ì´ë¯¸ì§€ URL ìˆ˜ì§‘ ({len(image_urls)}/{max_images}): {original_url}")
                    
                except Exception as e:
                    logger.debug(f"ì¸ë„¤ì¼ {i} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    continue
            
            logger.info(f"í‚¤ì›Œë“œ '{keyword}': {len(image_urls)}ê°œ URL ìˆ˜ì§‘ ì™„ë£Œ")
            return image_urls
            
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì˜¤ë¥˜ ({keyword}): {e}")
            return image_urls
        finally:
            if driver:
                driver.quit()
    
    def _scroll_to_load_images(self, driver: webdriver.Chrome, target_count: int):
        """ì´ë¯¸ì§€ ë¡œë”©ì„ ìœ„í•œ ìŠ¤í¬ë¡¤"""
        scroll_count = 0
        max_scrolls = 5
        
        while scroll_count < max_scrolls:
            # í˜ì´ì§€ ëê¹Œì§€ ìŠ¤í¬ë¡¤
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
            
            # í˜„ì¬ ë¡œë“œëœ ì´ë¯¸ì§€ ìˆ˜ í™•ì¸
            current_images = len(driver.find_elements(By.CSS_SELECTOR, "img[data-src]"))
            
            if current_images >= target_count:
                break
            
            # "ê²°ê³¼ ë”ë³´ê¸°" ë²„íŠ¼ í´ë¦­ ì‹œë„
            try:
                more_button = driver.find_element(By.XPATH, "//input[@value='ê²°ê³¼ ë”ë³´ê¸°' or @value='Show more results']")
                if more_button.is_displayed():
                    driver.execute_script("arguments[0].click();", more_button)
                    time.sleep(3)
            except:
                pass
            
            scroll_count += 1
    
    def _extract_original_image_url(self, driver: webdriver.Chrome) -> Optional[str]:
        """
        í´ë¦­ëœ ì´ë¯¸ì§€ì—ì„œ ì›ë³¸ URL ì¶”ì¶œ
        
        Args:
            driver: Selenium ë“œë¼ì´ë²„
            
        Returns:
            ì›ë³¸ ì´ë¯¸ì§€ URL ë˜ëŠ” None
        """
        try:
            # ë°©ë²• 1: ì˜¤ë¥¸ìª½ íŒ¨ë„ì˜ í° ì´ë¯¸ì§€ì—ì„œ URL ì¶”ì¶œ
            selectors = [
                "img[jsname='kn3ccd']",  # êµ¬ê¸€ ì´ë¯¸ì§€ ë·°ì–´ì˜ ë©”ì¸ ì´ë¯¸ì§€
                "img[jsname='HiaYvf']",  # ë‹¤ë¥¸ ë²„ì „ì˜ ë©”ì¸ ì´ë¯¸ì§€
                ".n3VNCb img",           # ì´ë¯¸ì§€ ì»¨í…Œì´ë„ˆ ë‚´ ì´ë¯¸ì§€
                ".islrc img"             # ì´ë¯¸ì§€ ê²°ê³¼ ì»¨í…Œì´ë„ˆ
            ]
            
            for selector in selectors:
                try:
                    img_element = driver.find_element(By.CSS_SELECTOR, selector)
                    img_url = img_element.get_attribute('src')
                    
                    if img_url and self._is_valid_image_url(img_url):
                        return img_url
                except:
                    continue
            
            # ë°©ë²• 2: í˜ì´ì§€ ì†ŒìŠ¤ì—ì„œ ì´ë¯¸ì§€ URL íŒ¨í„´ ì°¾ê¸°
            page_source = driver.page_source
            
            # ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ URL íŒ¨í„´ ê²€ìƒ‰
            url_patterns = [
                r'https://[^"\']*\.(?:jpg|jpeg|png|webp)[^"\']*',
                r'"(https://[^"]*\.(?:jpg|jpeg|png|webp)[^"]*)"',
                r"'(https://[^']*\.(?:jpg|jpeg|png|webp)[^']*)'"
            ]
            
            for pattern in url_patterns:
                matches = re.findall(pattern, page_source, re.IGNORECASE)
                for match in matches:
                    url = match if isinstance(match, str) else match[0]
                    if self._is_valid_image_url(url) and 'googleusercontent' not in url:
                        return url
            
            return None
            
        except Exception as e:
            logger.debug(f"ì›ë³¸ URL ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None
    
    def _is_valid_image_url(self, url: str) -> bool:
        """ì´ë¯¸ì§€ URL ìœ íš¨ì„± ê²€ì‚¬"""
        if not url or not url.startswith(('http://', 'https://')):
            return False
        
        # ì œì™¸í•  íŒ¨í„´ë“¤
        exclude_patterns = [
            'google.com/images/branding',
            'gstatic.com',
            'data:image',
            'base64',
            'logo',
            'icon',
            'button'
        ]
        
        url_lower = url.lower()
        if any(pattern in url_lower for pattern in exclude_patterns):
            return False
        
        # ìœ íš¨í•œ ì´ë¯¸ì§€ í™•ì¥ì í™•ì¸
        valid_extensions = ['.jpg', '.jpeg', '.png', '.webp', '.bmp']
        return any(ext in url_lower for ext in valid_extensions)
    
    def collect_images_for_category(self, category: str, max_images_per_keyword: int = 15) -> List[str]:
        """ì¹´í…Œê³ ë¦¬ë³„ ì´ë¯¸ì§€ URL ìˆ˜ì§‘"""
        if category not in self.search_keywords:
            logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬: {category}")
            return []
        
        all_urls = []
        keywords = self.search_keywords[category]
        
        for keyword in keywords:
            try:
                urls = self.collect_image_urls_from_keyword(keyword, max_images_per_keyword)
                all_urls.extend(urls)
                
                # í‚¤ì›Œë“œ ê°„ ëŒ€ê¸°
                time.sleep(5)
                
            except Exception as e:
                logger.error(f"í‚¤ì›Œë“œ '{keyword}' ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        # ì¤‘ë³µ ì œê±°
        unique_urls = list(set(all_urls))
        logger.info(f"ì¹´í…Œê³ ë¦¬ '{category}': {len(all_urls)}ê°œ â†’ ì¤‘ë³µì œê±° í›„ {len(unique_urls)}ê°œ")
        
        return unique_urls
    
    def collect_all_categories(self, max_images_per_category: int = 50) -> Dict[str, List[str]]:
        """ëª¨ë“  ì¹´í…Œê³ ë¦¬ ì´ë¯¸ì§€ ìˆ˜ì§‘"""
        results = {}
        
        for category in self.search_keywords.keys():
            logger.info(f"\nğŸ—ï¸ === {category.upper()} ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ ì‹œì‘ ===")
            
            # í‚¤ì›Œë“œë‹¹ ì´ë¯¸ì§€ ìˆ˜ ê³„ì‚°
            num_keywords = len(self.search_keywords[category])
            images_per_keyword = max(5, max_images_per_category // num_keywords)
            
            try:
                urls = self.collect_images_for_category(category, images_per_keyword)
                
                # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
                if len(urls) > max_images_per_category:
                    urls = urls[:max_images_per_category]
                
                results[category] = urls
                logger.info(f"âœ… {category} ì™„ë£Œ: {len(urls)}ê°œ URL")
                
                # ì¹´í…Œê³ ë¦¬ ê°„ ëŒ€ê¸°
                time.sleep(10)
                
            except Exception as e:
                logger.error(f"âŒ {category} ì‹¤íŒ¨: {e}")
                results[category] = []
        
        return results


def test_improved_crawler():
    """ê°œì„ ëœ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” ê°œì„ ëœ êµ¬ê¸€ ì´ë¯¸ì§€ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ë¹„í™œì„±í™”ë¡œ í…ŒìŠ¤íŠ¸ (ë””ë²„ê¹…ìš©)
    crawler = ImprovedGoogleImageCrawler(headless=False, timeout=30)
    
    # ë‹¨ì¼ í‚¤ì›Œë“œ í…ŒìŠ¤íŠ¸
    test_keyword = "ë²½ëŒ ì™¸ë²½"
    print(f"í…ŒìŠ¤íŠ¸ í‚¤ì›Œë“œ: {test_keyword}")
    
    urls = crawler.collect_image_urls_from_keyword(test_keyword, max_images=5)
    
    print(f"\nìˆ˜ì§‘ ê²°ê³¼: {len(urls)}ê°œ URL")
    for i, url in enumerate(urls, 1):
        print(f"  {i}. {url}")
    
    return len(urls) > 0


if __name__ == "__main__":
    success = test_improved_crawler()
    
    if success:
        print("\nâœ… ê°œì„ ëœ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
    else:
        print("\nâŒ ê°œì„ ëœ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")