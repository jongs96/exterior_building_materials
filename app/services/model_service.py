# -*- coding: utf-8 -*-
"""
ëª¨ë¸ ì„œë¹„ìŠ¤ - TensorFlow ëª¨ë¸ ë¡œë”© ë° ì˜ˆì¸¡
ê±´ì¶• ì™¸ì¥ì¬ ë¶„ë¥˜ë¥¼ ìœ„í•œ AI ëª¨ë¸ ì„œë¹„ìŠ¤ (ë”ë¯¸ ëª¨ë“œ ì—†ìŒ)
"""

import os
import numpy as np
from pathlib import Path
import logging
from typing import Optional, Dict, Any
import threading
import time

logger = logging.getLogger(__name__)

# TensorFlow ì§€ì—° ë¡œë”©ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
_tf = None
_tf_lock = threading.Lock()


def get_tensorflow():
    """TensorFlow ëª¨ë“ˆì„ ì§€ì—° ë¡œë”©í•˜ëŠ” í•¨ìˆ˜"""
    global _tf
    if _tf is None:
        with _tf_lock:
            if _tf is None:
                try:
                    import tensorflow as tf
                    _tf = tf
                    logger.info("TensorFlow ë¡œë“œ ì„±ê³µ")
                except Exception as e:
                    logger.error(f"TensorFlow ë¡œë“œ ì‹¤íŒ¨: {e}")
                    raise ImportError(f"TensorFlow ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    return _tf


class ModelService:
    """ê±´ì¶• ì™¸ì¥ì¬ ë¶„ë¥˜ ëª¨ë¸ ì„œë¹„ìŠ¤ (ì‹¤ì œ AI ëª¨ë¸ë§Œ ì‚¬ìš©)"""
    
    def __init__(self, model_path: str):
        """ëª¨ë¸ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.model_path = Path(model_path)
        self.model = None
        self.class_names = ['brick', 'metal', 'stone', 'stucco', 'wood']
        self.is_loaded = False
        self._load_lock = threading.Lock()
        
        logger.info(f"ModelService ì´ˆê¸°í™”: {self.model_path}")
    
    def load_model(self) -> bool:
        """ì‹¤ì œ TensorFlow ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œ"""
        if self.is_loaded:
            return True
            
        with self._load_lock:
            if self.is_loaded:
                return True
                
            try:
                # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
                if not self.model_path.exists():
                    raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
                
                # TensorFlow ë¡œë“œ
                tf = get_tensorflow()
                
                logger.info(f"ì‹¤ì œ ëª¨ë¸ ë¡œë”© ì‹œì‘: {self.model_path}")
                start_time = time.time()
                
                # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ëª¨ë¸ ë¡œë“œ ì‹œë„
                model_loaded = False
                
                # ë°©ë²• 1: ê¸°ë³¸ ë¡œë”©
                try:
                    self.model = tf.keras.models.load_model(str(self.model_path), compile=False)
                    model_loaded = True
                    logger.info("âœ… ê¸°ë³¸ ëª¨ë¸ ë¡œë”© ì„±ê³µ")
                except Exception as e1:
                    logger.warning(f"ê¸°ë³¸ ë¡œë”© ì‹¤íŒ¨: {e1}")
                    
                    # ë°©ë²• 2: í˜¸í™˜ì„± ëª¨ë“œ
                    try:
                        # TensorFlow 2.13ì—ì„œ batch_shape ë¬¸ì œ í•´ê²°
                        import tensorflow.keras.utils as utils
                        
                        # ì»¤ìŠ¤í…€ ê°ì²´ ì •ì˜
                        custom_objects = {
                            'InputLayer': tf.keras.layers.InputLayer
                        }
                        
                        self.model = tf.keras.models.load_model(
                            str(self.model_path), 
                            compile=False,
                            custom_objects=custom_objects
                        )
                        model_loaded = True
                        logger.info("âœ… í˜¸í™˜ì„± ëª¨ë“œ ë¡œë”© ì„±ê³µ")
                    except Exception as e2:
                        logger.error(f"í˜¸í™˜ì„± ëª¨ë“œë„ ì‹¤íŒ¨: {e2}")
                        
                        # ë°©ë²• 3: ê°€ì¤‘ì¹˜ë§Œ ë¡œë“œ
                        try:
                            logger.info("ê°€ì¤‘ì¹˜ ê¸°ë°˜ ëª¨ë¸ ì¬êµ¬ì„± ì‹œë„...")
                            self.model = self._create_model_architecture()
                            
                            # ê°€ì¤‘ì¹˜ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
                            if str(self.model_path).endswith('.h5'):
                                self.model.load_weights(str(self.model_path))
                                model_loaded = True
                                logger.info("âœ… ê°€ì¤‘ì¹˜ ê¸°ë°˜ ë¡œë”© ì„±ê³µ")
                        except Exception as e3:
                            logger.error(f"ê°€ì¤‘ì¹˜ ë¡œë”©ë„ ì‹¤íŒ¨: {e3}")
                
                if not model_loaded:
                    raise Exception("ëª¨ë“  ëª¨ë¸ ë¡œë”© ë°©ë²•ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                
                load_time = time.time() - start_time
                
                # ëª¨ë¸ ì›Œë°ì—…
                self._warmup_model()
                
                self.is_loaded = True
                logger.info(f"ğŸ‰ ì‹¤ì œ AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {load_time:.2f}ì´ˆ)")
                
                if hasattr(self.model, 'input_shape'):
                    logger.info(f"ì…ë ¥ í˜•íƒœ: {self.model.input_shape}")
                if hasattr(self.model, 'output_shape'):
                    logger.info(f"ì¶œë ¥ í˜•íƒœ: {self.model.output_shape}")
                
                return True
                
            except Exception as e:
                logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.is_loaded = False
                self.model = None
                raise Exception(f"ì‹¤ì œ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    
    def _create_model_architecture(self):
        """ê¸°ë³¸ CNN ì•„í‚¤í…ì²˜ ìƒì„± (ê°€ì¤‘ì¹˜ ë¡œë”©ìš©)"""
        tf = get_tensorflow()
        
        model = tf.keras.Sequential([
            tf.keras.layers.Input(shape=(224, 224, 3)),
            tf.keras.layers.Rescaling(1./255),
            
            # Conv ë¸”ë¡ë“¤
            tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(2, 2),
            
            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(2, 2),
            
            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(2, 2),
            
            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(2, 2),
            
            # ë¶„ë¥˜ê¸°
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(5, activation='softmax')
        ])
        
        return model
    
    def _warmup_model(self):
        """ëª¨ë¸ ì›Œë°ì—…"""
        try:
            if self.model is not None:
                dummy_input = np.random.random((1, 224, 224, 3)).astype(np.float32)
                _ = self.model.predict(dummy_input, verbose=0)
                logger.debug("ëª¨ë¸ ì›Œë°ì—… ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"ëª¨ë¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
    
    def is_model_loaded(self) -> bool:
        """ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸"""
        return self.is_loaded and self.model is not None
    
    def predict(self, image: np.ndarray) -> Optional[Dict[str, Any]]:
        """ì‹¤ì œ AI ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ë¶„ë¥˜ ì˜ˆì¸¡"""
        # ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë¡œë“œ ì‹œë„
        if not self.is_model_loaded():
            logger.info("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ. ë¡œë“œë¥¼ ì‹œë„í•©ë‹ˆë‹¤...")
            if not self.load_model():
                raise Exception("ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        try:
            start_time = time.time()
            
            # ì…ë ¥ ê²€ì¦
            if not isinstance(image, np.ndarray):
                raise ValueError("ì…ë ¥ì´ numpy ë°°ì—´ì´ ì•„ë‹™ë‹ˆë‹¤")
                
            if len(image.shape) != 4:
                raise ValueError(f"ì˜ëª»ëœ ì…ë ¥ í˜•íƒœ: {image.shape}. (1, 224, 224, 3) í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤")
            
            if image.shape[1:] != (224, 224, 3):
                raise ValueError(f"ì˜ëª»ëœ ì´ë¯¸ì§€ í¬ê¸°: {image.shape[1:]}. (224, 224, 3)ì´ì–´ì•¼ í•©ë‹ˆë‹¤")
            
            # ì‹¤ì œ ëª¨ë¸ ì˜ˆì¸¡ ì‹¤í–‰
            logger.debug(f"ì‹¤ì œ AI ëª¨ë¸ ì˜ˆì¸¡ ì‹¤í–‰ - ì…ë ¥ í˜•íƒœ: {image.shape}")
            predictions = self.model.predict(image, verbose=0)
            probabilities = predictions[0]
            
            # ê²°ê³¼ ì²˜ë¦¬
            predicted_class_idx = np.argmax(probabilities)
            predicted_class = self.class_names[predicted_class_idx]
            confidence = float(probabilities[predicted_class_idx])
            
            # ëª¨ë“  í´ë˜ìŠ¤ë³„ í™•ë¥ 
            class_probabilities = {
                class_name: float(prob) 
                for class_name, prob in zip(self.class_names, probabilities)
            }
            
            processing_time = time.time() - start_time
            
            result = {
                'predicted_class': predicted_class,
                'confidence': confidence,
                'probabilities': class_probabilities,
                'processing_time': processing_time,
                'model_type': 'real_ai'  # ì‹¤ì œ AI ëª¨ë¸ì„ì„ í‘œì‹œ
            }
            
            logger.info(f"ğŸ¤– ì‹¤ì œ AI ì˜ˆì¸¡ ì™„ë£Œ: {predicted_class} (ì‹ ë¢°ë„: {confidence:.3f}, ì²˜ë¦¬ì‹œê°„: {processing_time:.3f}ì´ˆ)")
            
            return result
            
        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise Exception(f"AI ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
    
    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        info = {
            'loaded': self.is_loaded,
            'model_path': str(self.model_path),
            'class_names': self.class_names,
            'num_classes': len(self.class_names),
            'model_type': 'real_ai'
        }
        
        if self.is_loaded and self.model is not None:
            try:
                info.update({
                    'input_shape': self.model.input_shape,
                    'output_shape': self.model.output_shape,
                    'model_layers': len(self.model.layers),
                    'trainable_params': self.model.count_params(),
                })
            except Exception as e:
                logger.debug(f"ëª¨ë¸ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return info
    
    def unload_model(self):
        """ë©”ëª¨ë¦¬ì—ì„œ ëª¨ë¸ ì–¸ë¡œë“œ"""
        with self._load_lock:
            if self.model is not None:
                del self.model
                self.model = None
                self.is_loaded = False
                logger.info("ëª¨ë¸ì´ ë©”ëª¨ë¦¬ì—ì„œ ì–¸ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤")


# í¸ì˜ í•¨ìˆ˜
def create_model_service(model_path: str) -> ModelService:
    """ModelService ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return ModelService(model_path)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ì‹¤ì œ AI ëª¨ë¸ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸")
    
    model_path = "exterior_material_cnn_v1.h5"
    if os.path.exists(model_path):
        service = create_model_service(model_path)
        print(f"ModelService ìƒì„± ì™„ë£Œ: {service}")
        
        info = service.get_model_info()
        print(f"ëª¨ë¸ ì •ë³´: {info}")
    else:
        print(f"ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")