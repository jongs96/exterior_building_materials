# -*- coding: utf-8 -*-
"""
PyTorch ëª¨ë¸ ì„œë¹„ìŠ¤ - ê±´ì¶• ì™¸ì¥ì¬ ë¶„ë¥˜
"""

import os
import numpy as np
from pathlib import Path
import logging
from typing import Optional, Dict, Any
import threading
import time

logger = logging.getLogger(__name__)

# PyTorch ì§€ì—° ë¡œë”©ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
_torch = None
_torch_lock = threading.Lock()


def get_torch():
    """PyTorch ëª¨ë“ˆì„ ì§€ì—° ë¡œë”©í•˜ëŠ” í•¨ìˆ˜"""
    global _torch
    if _torch is None:
        with _torch_lock:
            if _torch is None:
                try:
                    import torch
                    _torch = torch
                    logger.info("PyTorch ë¡œë“œ ì„±ê³µ")
                except Exception as e:
                    logger.error(f"PyTorch ë¡œë“œ ì‹¤íŒ¨: {e}")
                    raise ImportError(f"PyTorch ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    return _torch


class ModelService:
    """ê±´ì¶• ì™¸ì¥ì¬ ë¶„ë¥˜ PyTorch ëª¨ë¸ ì„œë¹„ìŠ¤"""
    
    def __init__(self, model_path: str):
        """ëª¨ë¸ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.model_path = Path(model_path)
        self.model = None
        self.class_names = ['brick', 'metal', 'stone', 'stucco', 'wood']
        self.is_loaded = False
        self.device = None
        self._load_lock = threading.Lock()
        
        logger.info(f"PyTorch ModelService ì´ˆê¸°í™”: {self.model_path}")
    
    def load_model(self) -> bool:
        """PyTorch ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œ"""
        if self.is_loaded:
            return True
            
        with self._load_lock:
            if self.is_loaded:
                return True
                
            try:
                # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
                if not self.model_path.exists():
                    raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
                
                # PyTorch ë¡œë“œ
                torch = get_torch()
                import torch.nn as nn
                from torchvision import models
                
                logger.info(f"PyTorch ëª¨ë¸ ë¡œë”© ì‹œì‘: {self.model_path}")
                start_time = time.time()
                
                # ë””ë°”ì´ìŠ¤ ì„¤ì •
                self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
                logger.info(f"ë””ë°”ì´ìŠ¤: {self.device}")
                
                # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
                checkpoint = torch.load(str(self.model_path), map_location=self.device)
                
                # ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡° í™•ì¸
                if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                    state_dict = checkpoint['model_state_dict']
                    if 'class_names' in checkpoint:
                        self.class_names = checkpoint['class_names']
                        logger.info(f"ì €ì¥ëœ í´ë˜ìŠ¤: {self.class_names}")
                else:
                    state_dict = checkpoint
                
                # ëª¨ë¸ êµ¬ì¡° ì¶”ë¡  (layer3ì˜ ë¸”ë¡ ìˆ˜ë¡œ ResNet íƒ€ì… í™•ì¸)
                layer3_blocks = [k for k in state_dict.keys() if k.startswith('layer3.')]
                max_block = max([int(k.split('.')[1]) for k in layer3_blocks if k.split('.')[1].isdigit()], default=1)
                
                if max_block >= 5:  # ResNet50
                    logger.info("ëª¨ë¸ íƒ€ì…: ResNet50")
                    self.model = models.resnet50(weights=None)
                    
                    # FC ë ˆì´ì–´ êµ¬ì¡° í™•ì¸
                    if 'fc.1.weight' in state_dict:
                        logger.info("FC ë ˆì´ì–´: Sequential (Dropout + Linear)")
                        num_features = self.model.fc.in_features
                        self.model.fc = nn.Sequential(
                            nn.Dropout(0.3),
                            nn.Linear(num_features, 512),
                            nn.ReLU(),
                            nn.Dropout(0.2),
                            nn.Linear(512, len(self.class_names))
                        )
                    else:
                        logger.info("FC ë ˆì´ì–´: Simple Linear")
                        num_features = self.model.fc.in_features
                        self.model.fc = nn.Linear(num_features, len(self.class_names))
                else:  # ResNet18
                    logger.info("ëª¨ë¸ íƒ€ì…: ResNet18")
                    self.model = models.resnet18(weights=None)
                    num_features = self.model.fc.in_features
                    self.model.fc = nn.Linear(num_features, len(self.class_names))
                
                # ê°€ì¤‘ì¹˜ ë¡œë“œ
                self.model.load_state_dict(state_dict)
                self.model = self.model.to(self.device)
                self.model.eval()
                
                load_time = time.time() - start_time
                
                # ëª¨ë¸ ì›Œë°ì—…
                self._warmup_model()
                
                self.is_loaded = True
                logger.info(f"ğŸ‰ PyTorch ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {load_time:.2f}ì´ˆ)")
                
                return True
                
            except Exception as e:
                logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()
                self.is_loaded = False
                self.model = None
                raise Exception(f"PyTorch ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    
    def _warmup_model(self):
        """ëª¨ë¸ ì›Œë°ì—…"""
        try:
            if self.model is not None:
                torch = get_torch()
                dummy_input = torch.randn(1, 3, 224, 224).to(self.device)
                with torch.no_grad():
                    _ = self.model(dummy_input)
                logger.debug("ëª¨ë¸ ì›Œë°ì—… ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"ëª¨ë¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
    
    def is_model_loaded(self) -> bool:
        """ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸"""
        return self.is_loaded and self.model is not None
    
    def predict(self, image: np.ndarray) -> Optional[Dict[str, Any]]:
        """PyTorch ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ë¶„ë¥˜ ì˜ˆì¸¡"""
        # ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë¡œë“œ ì‹œë„
        if not self.is_model_loaded():
            logger.info("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ. ë¡œë“œë¥¼ ì‹œë„í•©ë‹ˆë‹¤...")
            if not self.load_model():
                raise Exception("ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        try:
            torch = get_torch()
            start_time = time.time()
            
            # ì…ë ¥ ê²€ì¦
            if not isinstance(image, np.ndarray):
                raise ValueError("ì…ë ¥ì´ numpy ë°°ì—´ì´ ì•„ë‹™ë‹ˆë‹¤")
                
            if len(image.shape) != 4:
                raise ValueError(f"ì˜ëª»ëœ ì…ë ¥ í˜•íƒœ: {image.shape}. (1, 224, 224, 3) í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤")
            
            if image.shape[1:] != (224, 224, 3):
                raise ValueError(f"ì˜ëª»ëœ ì´ë¯¸ì§€ í¬ê¸°: {image.shape[1:]}. (224, 224, 3)ì´ì–´ì•¼ í•©ë‹ˆë‹¤")
            
            # NumPy (H, W, C) -> PyTorch (C, H, W) ë³€í™˜
            # ì…ë ¥: (1, 224, 224, 3) -> (1, 3, 224, 224)
            # ì£¼ì˜: image_serviceì—ì„œ ì´ë¯¸ ì •ê·œí™”ê°€ ì™„ë£Œëœ ìƒíƒœ
            image_tensor = torch.from_numpy(image).permute(0, 3, 1, 2).float()
            image_tensor = image_tensor.to(self.device)
            
            # ì˜ˆì¸¡ ì‹¤í–‰
            logger.debug(f"PyTorch ëª¨ë¸ ì˜ˆì¸¡ ì‹¤í–‰ - ì…ë ¥ í˜•íƒœ: {image_tensor.shape}")
            
            with torch.no_grad():
                outputs = self.model(image_tensor)
                probabilities = torch.softmax(outputs, dim=1)[0]
            
            # CPUë¡œ ì´ë™ ë° NumPy ë³€í™˜
            probabilities = probabilities.cpu().numpy()
            
            # ê²°ê³¼ ì²˜ë¦¬
            predicted_class_idx = np.argmax(probabilities)
            predicted_class = self.class_names[predicted_class_idx]
            confidence = float(probabilities[predicted_class_idx])
            
            # ëª¨ë“  í´ë˜ìŠ¤ë³„ í™•ë¥ 
            class_probabilities = {
                class_name: float(prob) 
                for class_name, prob in zip(self.class_names, probabilities)
            }
            
            processing_time = time.time() - start_time
            
            result = {
                'predicted_class': predicted_class,
                'confidence': confidence,
                'probabilities': class_probabilities,
                'processing_time': processing_time,
                'model_type': 'pytorch_resnet'
            }
            
            logger.info(f"ğŸ¤– PyTorch ì˜ˆì¸¡ ì™„ë£Œ: {predicted_class} (ì‹ ë¢°ë„: {confidence:.3f}, ì²˜ë¦¬ì‹œê°„: {processing_time:.3f}ì´ˆ)")
            
            return result
            
        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            raise Exception(f"PyTorch ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
    
    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        info = {
            'loaded': self.is_loaded,
            'model_path': str(self.model_path),
            'class_names': self.class_names,
            'num_classes': len(self.class_names),
            'model_type': 'pytorch_resnet',
            'device': str(self.device) if self.device else 'not_set'
        }
        
        if self.is_loaded and self.model is not None:
            try:
                # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
                total_params = sum(p.numel() for p in self.model.parameters())
                trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
                
                info.update({
                    'total_params': total_params,
                    'trainable_params': trainable_params,
                })
            except Exception as e:
                logger.debug(f"ëª¨ë¸ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return info
    
    def unload_model(self):
        """ë©”ëª¨ë¦¬ì—ì„œ ëª¨ë¸ ì–¸ë¡œë“œ"""
        with self._load_lock:
            if self.model is not None:
                del self.model
                self.model = None
                self.is_loaded = False
                logger.info("ëª¨ë¸ì´ ë©”ëª¨ë¦¬ì—ì„œ ì–¸ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤")


# í¸ì˜ í•¨ìˆ˜
def create_model_service(model_path: str) -> ModelService:
    """ModelService ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return ModelService(model_path)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("PyTorch ëª¨ë¸ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸")
    
    model_path = "building_material_classifier_pytorch.pth"
    if os.path.exists(model_path):
        service = create_model_service(model_path)
        print(f"ModelService ìƒì„± ì™„ë£Œ: {service}")
        
        try:
            service.load_model()
            info = service.get_model_info()
            print(f"ëª¨ë¸ ì •ë³´: {info}")
        except Exception as e:
            print(f"ì˜¤ë¥˜: {e}")
    else:
        print(f"ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
