# -*- coding: utf-8 -*-
"""
ë¹ ë¥¸ PyTorch ëª¨ë¸ í•™ìŠµ (ìµœì í™” ë²„ì „)
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
from pathlib import Path
import time

def train_fast_model():
    """ìµœì í™”ëœ ë¹ ë¥¸ ëª¨ë¸ í•™ìŠµ"""
    print("ğŸš€ ë¹ ë¥¸ PyTorch ëª¨ë¸ í•™ìŠµ")
    print("=" * 60)
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ë””ë°”ì´ìŠ¤: {device}")
    
    # ê°„ë‹¨í•œ ë°ì´í„° ë³€í™˜ (ì†ë„ ìµœì í™”)
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    # ë°ì´í„°ì…‹ ë¡œë”©
    print("\nğŸ“‚ ë°ì´í„°ì…‹ ë¡œë”©...")
    data_dir = Path("data/raw")
    
    # ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ
    full_dataset = datasets.ImageFolder(data_dir)
    
    # í›ˆë ¨/ê²€ì¦ ë¶„í•  (80/20)
    train_size = int(0.8 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    
    train_dataset, val_dataset = torch.utils.data.random_split(
        full_dataset, 
        [train_size, val_size],
        generator=torch.Generator().manual_seed(123)
    )
    
    # Transform ì ìš©
    train_dataset.dataset.transform = train_transform
    val_dataset.dataset.transform = val_transform
    
    # DataLoader ìƒì„± (ë°°ì¹˜ í¬ê¸° ì¦ê°€, num_workers=0ìœ¼ë¡œ Windows í˜¸í™˜)
    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0, pin_memory=False)
    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=0, pin_memory=False)
    
    class_names = full_dataset.classes
    print(f"í´ë˜ìŠ¤: {class_names}")
    print(f"í›ˆë ¨ ë°ì´í„°: {len(train_dataset)}ê°œ")
    print(f"ê²€ì¦ ë°ì´í„°: {len(val_dataset)}ê°œ")
    print(f"ë°°ì¹˜ í¬ê¸°: 64")
    
    # ê°€ë²¼ìš´ ëª¨ë¸ ì‚¬ìš© (ResNet18)
    print("\nğŸ—ï¸ ResNet18 ëª¨ë¸ ìƒì„± (ë¹ ë¥¸ í•™ìŠµìš©)...")
    model = models.resnet18(pretrained=True)
    
    # ë§ˆì§€ë§‰ FC ë ˆì´ì–´ë§Œ êµì²´
    num_features = model.fc.in_features
    model.fc = nn.Linear(num_features, len(class_names))
    
    model = model.to(device)
    
    # ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)
    
    # í•™ìŠµ
    print("\nğŸ¯ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    print("=" * 60)
    
    best_val_acc = 0.0
    epochs = 15  # ì—í¬í¬ ìˆ˜ ê°ì†Œ
    
    total_start = time.time()
    
    for epoch in range(epochs):
        epoch_start = time.time()
        
        # í›ˆë ¨ ëª¨ë“œ
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        for batch_idx, (images, labels) in enumerate(train_loader):
            images, labels = images.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            train_total += labels.size(0)
            train_correct += (predicted == labels).sum().item()
        
        train_acc = train_correct / train_total
        
        # ê²€ì¦ ëª¨ë“œ
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                
                val_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                val_total += labels.size(0)
                val_correct += (predicted == labels).sum().item()
        
        val_acc = val_correct / val_total
        
        # í•™ìŠµë¥  ì¡°ì •
        scheduler.step()
        
        epoch_time = time.time() - epoch_start
        
        print(f"Epoch {epoch+1:2d}/{epochs} ({epoch_time:.1f}s) - "
              f"Train: {train_acc:.3f} ({train_acc*100:.1f}%) - "
              f"Val: {val_acc:.3f} ({val_acc*100:.1f}%)")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_acc': val_acc,
                'class_names': class_names
            }, 'building_material_classifier_pytorch.pth')
            print(f"  âœ… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥!")
        
        # ì¡°ê¸° ì¢…ë£Œ (75% ë‹¬ì„± ì‹œ)
        if val_acc >= 0.75:
            print(f"\nğŸ‰ ëª©í‘œ ë‹¬ì„±! 75% ì´ìƒ ì •í™•ë„!")
            break
    
    total_time = time.time() - total_start
    
    print(f"\n{'='*60}")
    print(f"ì´ í•™ìŠµ ì‹œê°„: {total_time:.1f}ì´ˆ ({total_time/60:.1f}ë¶„)")
    print(f"ìµœê³  ê²€ì¦ ì •í™•ë„: {best_val_acc:.3f} ({best_val_acc*100:.1f}%)")
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ
    checkpoint = torch.load('building_material_classifier_pytorch.pth')
    model.load_state_dict(checkpoint['model_state_dict'])
    
    # ìµœì¢… í‰ê°€
    print("\nğŸ“Š ìµœì¢… í‰ê°€...")
    model.eval()
    
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for images, labels in val_loader:
            images = images.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.numpy())
    
    # í´ë˜ìŠ¤ë³„ ì •í™•ë„
    print("\nğŸ“Š í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:")
    print("-" * 40)
    
    class_correct = [0] * len(class_names)
    class_total = [0] * len(class_names)
    
    for pred, label in zip(all_preds, all_labels):
        class_total[label] += 1
        if pred == label:
            class_correct[label] += 1
    
    for i, class_name in enumerate(class_names):
        if class_total[i] > 0:
            accuracy = class_correct[i] / class_total[i]
            print(f"{class_name:8}: {accuracy:.3f} ({accuracy*100:.1f}%) - {class_correct[i]}/{class_total[i]}")
    
    overall_acc = sum(class_correct) / sum(class_total)
    print("-" * 40)
    print(f"ì „ì²´    : {overall_acc:.3f} ({overall_acc*100:.1f}%) - {sum(class_correct)}/{sum(class_total)}")
    
    print(f"\nğŸ’¾ ìµœì¢… ëª¨ë¸ ì €ì¥: building_material_classifier_pytorch.pth")
    
    return model, class_names

if __name__ == "__main__":
    try:
        model, class_names = train_fast_model()
        print("\nğŸ‰ PyTorch ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
